{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c1c2cc-6548-4582-9cb6-03a5e2d1057a",
   "metadata": {},
   "source": [
    "# 1. Install and import required modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34dcc01-db14-41ee-89d1-0ea968755314",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8dcc5-7b98-4a81-a6e3-f82a52d9476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15874abc-7370-4de3-ad02-0b0306d5b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686d46e-8d69-4f09-9054-a0fbf3fa4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f8f417-46ee-43d0-aed9-1efa24e05a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3932d59f-653c-4487-abbe-394dfb786421",
   "metadata": {},
   "source": [
    "# 2. Downloadng ssl certificate in case of necessary case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b64cf1-d708-48b9-af39-6f12aaefb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615c3b9-79a8-4c7d-ba69-d0e08e533453",
   "metadata": {},
   "source": [
    "# 3. Importing ultralytics small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1690b46-5b96-4e56-a9c1-5d095214fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s',pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b38af7-422e-4911-bcb5-0f69018faba9",
   "metadata": {},
   "source": [
    "## 3.1 Model internal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbb02f-f4b4-4ae9-9033-76cd8b5e8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3505852-875c-48ec-af7f-89128a29484d",
   "metadata": {},
   "source": [
    "### 3.1.1 Make manual detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f90d3e-e841-4a19-948a-c8d22aab462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'https://media.cntraveler.com/photos/53e2f41cdddaa35c30f66775/master/pass/highway-traffic.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71461ccd-5fdd-4ad5-9a41-b99a18148585",
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6f46d-8f26-4500-bd06-202940060230",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34f657-aeae-4339-aa0d-787f91afd74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74e542-195c-4d9f-b8a9-fad7372901a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff7a867-684c-49a3-bb64-7476c8ced5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db38096e-f8d7-42dd-b255-046361ade598",
   "metadata": {},
   "source": [
    "### Realtime detection through opencv library and render the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe31abba-5fe2-49cc-b129-9a906a368f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame  = cap.read()\n",
    "    \n",
    "\n",
    "    results = model(frame)\n",
    "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bdc53a-cc5c-45f0-8e72-1165d001ede5",
   "metadata": {},
   "source": [
    "# 6. Training the model from scratch with customize classes and own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438bcad9-f635-4630-9006-09a91416e10e",
   "metadata": {},
   "source": [
    "## 6.1 Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f481cb-2a85-4c04-8ca7-91c96cc9797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ed1e14-17df-4501-8e12-8a3f530797fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join('data', 'images')\n",
    "labels = ['awake', 'drowsy']\n",
    "number_imgs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64338d-4c5e-4663-9799-ab133d478c8e",
   "metadata": {},
   "source": [
    "### Collecting images through realtime straming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd42875-3ee2-487f-8e42-f1ffe90a8119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for awake\n",
      "Collecting images for awake, image number 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 16:04:56.361 Python[4735:10722074] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for awake, image number 1\n",
      "Collecting images for awake, image number 2\n",
      "Collecting images for awake, image number 3\n",
      "Collecting images for awake, image number 4\n",
      "Collecting images for awake, image number 5\n",
      "Collecting images for awake, image number 6\n",
      "Collecting images for awake, image number 7\n",
      "Collecting images for awake, image number 8\n",
      "Collecting images for awake, image number 9\n",
      "Collecting images for awake, image number 10\n",
      "Collecting images for awake, image number 11\n",
      "Collecting images for awake, image number 12\n",
      "Collecting images for awake, image number 13\n",
      "Collecting images for awake, image number 14\n",
      "Collecting images for awake, image number 15\n",
      "Collecting images for awake, image number 16\n",
      "Collecting images for awake, image number 17\n",
      "Collecting images for awake, image number 18\n",
      "Collecting images for awake, image number 19\n",
      "Collecting images for drowsy\n",
      "Collecting images for drowsy, image number 0\n",
      "Collecting images for drowsy, image number 1\n",
      "Collecting images for drowsy, image number 2\n",
      "Collecting images for drowsy, image number 3\n",
      "Collecting images for drowsy, image number 4\n",
      "Collecting images for drowsy, image number 5\n",
      "Collecting images for drowsy, image number 6\n",
      "Collecting images for drowsy, image number 7\n",
      "Collecting images for drowsy, image number 8\n",
      "Collecting images for drowsy, image number 9\n",
      "Collecting images for drowsy, image number 10\n",
      "Collecting images for drowsy, image number 11\n",
      "Collecting images for drowsy, image number 12\n",
      "Collecting images for drowsy, image number 13\n",
      "Collecting images for drowsy, image number 14\n",
      "Collecting images for drowsy, image number 15\n",
      "Collecting images for drowsy, image number 16\n",
      "Collecting images for drowsy, image number 17\n",
      "Collecting images for drowsy, image number 18\n",
      "Collecting images for drowsy, image number 19\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Loop through labels \n",
    "for label in labels:\n",
    "    print(f'Collecting images for {label}')\n",
    "    time.sleep(5)\n",
    "\n",
    "    # loop through image range \n",
    "    for img_num in range(number_imgs):\n",
    "        \n",
    "        print(f'Collecting images for {label}, image number {img_num}')\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        imgname = os.path.join(IMAGE_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        \n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('Image collection', frame)\n",
    "        \n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1956a2-01c7-48ec-a1ee-93decba59bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HumanSignal/labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582cbaf4-ce3e-4683-b137-2b92bb530664",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyqt5 lxml # Install qt and lxml by pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd204de-ad2c-4fda-bb37-097ebc229a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/psm/Desktop/Final v1/labelImg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd labelImg && pyrcc5 -o libs/resources.py resources.qrc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe60c3-1b32-4bd7-9959-96c81d331f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8ffb5-71fc-41a4-bd23-7a44be1331e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py --img 320 --batch 16 --epochs 5 --data dataset.yml --weights yolov5s.pt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38547ee-6e83-4c3c-9365-a9719399c29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a6968cc-6e43-4ff8-93b9-3b06eb06d7c6",
   "metadata": {},
   "source": [
    "# 7. Load the custome model according to the customize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe7e2c-8b27-4d5b-9207-12a74e85c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path = \"runs/train/exp2/weights/last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9d3ff-f75a-4869-935c-bd65086f5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img  = os.path.join('../data', 'images', 'drowsy.774e231e-fa09-11ee-aa9a-c24ecc92889a.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85563c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb50fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2465b44d-775f-4235-a57b-19649612051e",
   "metadata": {},
   "source": [
    "# 8 realtime detection and clssification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc493879-71cc-4295-85a3-2494113823a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame  = cap.read()\n",
    "    \n",
    "\n",
    "    results = model(frame)\n",
    "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
